type: Attribute
spec:
  name: KeyStringIdentifier
  orc: OrcString
  presto: PrestoVarchar
  sql: SQLVarchar
---
type: Attribute
spec:
  name: NumericIdentifier
  orc: OrcBigint
  presto: PrestoBigint
  sql: SQLBigint
---
type: Attribute
spec:
  name: NullableStringIdentifier
  orc: OrcString
  presto: PrestoVarchar
  sql: SQLVarchar
---
type: Attribute
spec:
  name: NullablePOSIXTimestamp
  orc: OrcBigint
  presto: PrestoBigint
  sql: SQLBigint
---
type: Attribute
spec:
  name: NullableInt64
  orc: OrcBigint
  presto: PrestoBigint
  sql: SQLBigint
---
type: Attribute
spec:
  name: NullableString
  orc: OrcString
  presto: PrestoVarchar
  sql: SQLVarchar
---
type: Attribute
spec:
  name: FloatLatitude
  orc: OrcFloat
  presto: PrestoReal
  sql: SQLReal
---
type: Attribute
spec:
  name: FloatLongitude
  orc: OrcFloat
  presto: PrestoReal
  sql: SQLReal
---
type: Attribute
spec:
  name: URI
  orc: OrcString
  presto: PrestoVarchar
  sql: SQLVarchar
---
type: Constraint
spec:
  name: IsConsistent
  root: ParsedDataSetup
  requires:
    - ReplicatedDataSets
---
type: Constraint
spec:
  name: ReplicatedDataSets
  root: DataSet
  requires:
    - ReplicatedAssets
---
type: Constraint
spec:
  name: ReplicatedAssets
  root: Asset
  requires:
    - ReplicatedSchema
    - ReplicatedData
---
type: Constraint
spec:
  name: ReplicatedSchema
  root: StaticDataTable
  requires:
      - HiveSchemasCreated
---
type: Constraint
spec:
  name: HiveSchemasCreated
  root: HiveTableStorage
  requiresProgram: true
---
type: Constraint
spec:
  name: IsAuditedTable
  root: StaticDataTable
  requires:
    - IsConsistent
---
type: Constraint
spec:
  name: IsAudited
  root: ParsedDataSetup
  requires:
    - IsAuditedTable
---
type: Constraint
spec:
  name: ReplicatedData
  root: RemoteImportStorageSetup
  requires:
    - DownloadDataFromRemote
    - UploadDataToLocal
    - DataFromRemoteDownloaded
---
type: Constraint
spec:
  name: DataFromRemoteDownloaded
  root: RemoteImportStorageSetup
  requires:
    - DownloadDataFromRemote
    - RemoveFileHeader
---
type: Constraint
spec:
  name: DownloadDataFromRemote
  root: RemoteStorage
  requires:
    - DownloadDataFromRemoteGCSLocation
---
type: Constraint
spec:
  name: DownloadDataFromRemoteGCSLocation
  root: GCSLocation
  requiresProgram: true
---
type: Constraint
spec:
  name: RemoveFileHeader
  root: FileHeader
  requires:
    - FileIsDecompressed
  requiresProgram: true
---
type: Constraint
spec:
  name: FileIsDecompressed
  root: RemoteStorage
  requires:
    - Decompress
---
type: Constraint
spec:
  name: Decompress
  root: GzipCompression
  requires:
    - DownloadDataFromRemote
  requiresProgram: true
---
type: Constraint
spec:
  name: ConvertCSVToOrc
  root: RemoteImportStorageSetup
  requires:
      - DataFromRemoteDownloaded
  requiresProgram: true
---
type: Constraint
spec:
  name: UploadDataToLocal
  root: HiveLocation
  requires:
      - ConvertCSVToOrc
---
type: Program
spec:
  use: DownloadDataFromRemoteGCSLocation
  root: GCSLocation
  dialect: Python
  preamble: |
    from google.cloud import storage
    def download_blob_to_file(bucket_name, blob_name, tmp_dir, file_name):
      client = storage.Client.from_service_account_json('/gcloud/social_norms.json')
      bucket = client.bucket(bucket_name)
      blob = bucket.blob(blob_name)
      dest = "%s/%s" % (tmp_dir, file_name)
      blob.download_to_filename(dest)
  call: download_blob_to_file
  args:
    - type: AncestorArgument
      spec:
        call: gcs_location.bucket
        attaches: GCSLocation
    - type: AncestorArgument
      spec:
        call: gcs_location.blob
        attaches: GCSLocation
    - type: AncestorArgument
      spec:
        call: remote_import_storage_setup.tmp_dir
        attaches: RemoteImportStorageSetup
    - type: AncestorArgument
      spec:
        call: static_data_table.name
        attaches: StaticDataTable
---
type: Program
spec:
  use: Decompress
  root: GzipCompression
  dialect: Bash
  call: gunzip {tmp_dir}/{file_name}
  kwargs:
    tmp_dir:
      type: AncestorArgument
      spec:
        call: remote_import_storage_setup.tmp_dir
        attaches: RemoteImportStorageSetup
        name: tmp_dir
    file_name:
      type: AncestorArgument
      spec:
        call: static_data_table.name
        attaches: StaticDataTable
        name: file_name
---
type: Program
spec:
  use: RemoveFileHeader
  root: FileHeader
  dialect: Bash
  call: |
    tail -n +{n} {tmp_dir}/{file_name} > {tmp_dir}/{file_name}.no_header &&
    rm {tmp_dir}/{file_name}
  kwargs:
    n:
      type: AncestorArgument
      spec:
        attaches: FileHeader
        call: format!("{}", file_header.get_num_lines() + 1)
    tmp_dir:
      type: AncestorArgument
      spec:
        call: remote_import_storage_setup.tmp_dir
        attaches: RemoteImportStorageSetup
        name: tmp_dir
    file_name:
      type: AncestorArgument
      spec:
        call: static_data_table.name
        attaches: StaticDataTable
        name: file_name
---
type: DataSetup
spec:
  name: basic_data_setup
  users:
  - bogdan
  - alice
  - bob
  - alex
  - victor
  - john
  groups:
  - finance-users
  - datascience-users
  - project-crowding-detection
  datasets:
  - sentinel-2-metadata-dataset
  - snap-dataset
  role_bindings:
  - bogdan-global-permissions-admin
  endpoints:
    alluxio:
      server: alluxio
      rpcPort: 19999
      apiPort: 39999
    presto:
      server: presto-coordinator-0
      httpPort: 8080
    ranger:
      server: localhost
      port: 30800
      user: admin
      password: G0powerRangers
    gitea:
      server: localhost
      port: 30807
      token: 2b44b07e042ee9fe374e3eeebd2c9098468b5774
  imports:
  - type: LocalFileImport
    filename: users.yaml
  - type: LocalFileImport
    filename: snap.yaml
  constraints:
    - IsConsistent
---
type: RoleBinding
spec:
  user_name: bogdan
  name: bogdan-global-permissions-admin
  role:
    type: GlobalPermissionsAdmin
    spec: {}
---
type: UserGroup
spec:
  name: finance-users
  members:
    - alice
  labels:
    department: finance
---
type: UserGroup
spec:
  name: datascience-users
  members:
    - bogdan
  labels:
    department: datascience
---
type: UserGroup
spec:
  name: project-crowding-detection
  members:
    - bogdan
  labels:
    project: crowding-detection
---
type: DataSet
spec:
  tag: sentinel
  name: sentinel-2-metadata-dataset
  accessPolicies:
  - type: ApproveAccessSelector
    spec:
      matchLabels:
        department:
          - datascience
        project:
          - crowding-detection
  datumTemplates:
  - name: granule-datum
    type: KeyedStruct
    attributes:
    - name: granule_id
      type: KeyStringIdentifier
    - name: product_id
      type: NullableStringIdentifier
    - name: datatake_identifier
      type: NullableStringIdentifier
    - name: mgrs_tile
      type: NullableStringIdentifier
    - name: sensing_time
      type: NullablePOSIXTimestamp
    - name: total_size
      type: NullableInt64
    - name: cloud_cover
      type: NullableString
    - name: geometric_quality_flag
      type: NullableString
    - name: generation_time
      type: NullablePOSIXTimestamp
    - name: north_lat
      type: FloatLatitude
      comment: |
        Northern latitude of the tile`s bounding box.
    - name: south_lat
      type: FloatLatitude
      comment: |
        Southern latitude of the tile`s bounding box.
    - name: west_lon
      type: FloatLongitude
      comment: |
        Western longitude of the tile`s bounding box.
    - name: east_lon
      type: FloatLongitude
      comment: |
        Eastern longitude of the tile`s bounding box.
    - name: base_url
      type: URI
  assets:
    - type: StaticDataTable
      spec:
        tag: sentinel
        name: sentinel-2-metadata-table
        setup:
          type: RemoteImportStorageSetup
          spec:
            tmp_dir: /tmp/sentinel2
            remote:
              type: RemoteStorage
              location:
                type: GCSLocation
                spec:
                  tag: sentinel_location
                  bucket: gcp-public-data-sentinel2
                  blob: index.csv.gz-backup
              layout:
                type: SingleFileLayout
              encoding:
                type: CSVEncoding
                spec:
                  compression:
                    type: GzipCompression
                  header:
                    type: UpperSnakeCaseCSVHeader
            local:
            - type: HiveTableStorage
              location:
                type: AlluxioLocation
                spec:
                  path: 'sentinel2/metadata'
              layout:
                type: StaticHiveTableLayout
                spec: {}
              encoding:
                type: ORCEncoding
                spec: {}
        schema:
          type: TabularSchema
          spec:
            datumTemplateName: granule-datum
            attributes:
            - granule_id
            - product_id
            - datatake_identifier
            - mgrs_tile
            - sensing_time
            - total_size
            - cloud_cover
            - geometric_quality_flag
            - generation_time
            - north_lat
            - south_lat
            - west_lon
            - east_lon
            - base_url
---
type: Program
spec:
  use: ConvertCSVToOrc
  root: RemoteImportStorageSetup
  dialect: Bash
  call: >
    csv-import {tmp_dir}/{table_name}.no_header
    {tmp_dir}/{table_name}.no_header
  kwargs:
    tmp_dir:
      type: AncestorArgument
      spec:
        call: remote_import_storage_setup.tmp_dir
        attaches: RemoteImportStorageSetup
    table_name:
      type: AncestorArgument
      spec:
        call: static_data_table.name
        attaches: StaticDataTable
    schema:
      type: MultipleAncestorsArgument
      spec:
        call: >
          {
            let DataSchema::TabularSchema(ref t) = static_data_table.schema;
            let attributes = t.attributes.clone();
            let attr_v = data_set
                .datumTemplates
                .iter()
                .filter(|x| {
                    x.get_name().clone() == t.datumTemplateName
                })
                .map(|x| match x {
                    DatumTemplate::KeyedStruct(k) => k.attributes.clone(),
                    DatumTemplate::IdentifierTuple(t) => t.attributes.clone(),
                })
                .next().unwrap();
            let attr_map = attr_v.iter()
                .map(|x| (x.get_name().clone(), x.get_orc_type()))
                .collect::<HashMap<String, String>>();
            let attr_types = attributes.iter().map(
                |x| format!(
                    "{}:{}",
                    x,
                    attr_map.get(x).unwrap().clone()
                ).to_string()
            ).collect::<Vec<String>>();
            attr_types.join(",")
          }
        attaches:
          - StaticDataTable
          - DataSet
---
type: Program
spec:
  use: HiveSchemasCreated
  root: HiveTableStorage
  dialect: Presto
  call: |
    CREATE TABLE IF NOT EXISTS {table_name} (
    {schema}
    ) WITH (format='{data_format}');
  kwargs:
    table_name:
      type: AncestorArgument
      spec:
        call: static_data_table.name
        attaches: StaticDataTable
    data_format:
      type: AncestorArgument
      spec:
        call: >
          match &hive_table_storage.encoding {
            Encoding::ORCEncoding(_) => "ORC".to_string(),
            _ => panic!("Format not supported for hive table")
          }
        attaches: HiveTableStorage
    schema:
      type: MultipleAncestorsArgument
      spec:
        call: >
          {
            use crate::attributes::TAttribute;
            let DataSchema::TabularSchema(ref t) = static_data_table.schema;
            let attr_v = data_set
                .datumTemplates
                .iter()
                .filter(|x| {
                    x.get_name().clone() == t.datumTemplateName
                })
                .map(|x| match x {
                    DatumTemplate::KeyedStruct(k) => k.attributes.clone(),
                    DatumTemplate::IdentifierTuple(t) => t.attributes.clone(),
                })
                .next().unwrap();
            let attr_map = attr_v.iter()
                .map(|x|
                    (x.get_name().clone(), (x.get_presto_type(), x.get_comment().clone())))
                .collect::<Vec<_>>();
            let attr_types = attr_map.iter().map(|x| {
                let (name, (presto_type, comment)) = x;
                let comment_str = match comment {
                    Some(c) => format!(" COMMENT '{}'", c.replace("\n", "")),
                    None => "".to_string(),
                };
                format!(
                    "    {} {}{}",
                    name,
                    presto_type,
                    comment_str,
                ).to_string()
            }).collect::<Vec<String>>();
            format!("{}", attr_types.join(",\n"))
          }
        attaches:
          - StaticDataTable
          - DataSet
