---
type: Constraint
spec:
  name: Replicated
  root: Universe
  requires:
    - ReplicatedDataSets
---
type: Constraint
spec:
  name: ReplicatedDataSets
  root: DataSet
  requires:
    - ReplicatedAssets
---
type: Constraint
spec:
  name: ReplicatedAssets
  root: Asset
  requires:
    - ReplicatedSchema
    - DroppedCSVTable
    - TableSchemasCreated
    - UploadDataToLocal
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>| {
        use crate::storage_setup::*;
        if let StorageSetup::ReplicationStorageSetup(_) = ancestry.asset(root.clone()).unwrap().get_storage_setup() {
          return true;
        }
        false
      }
---
type: Constraint
spec:
  name: ReplicatedSchema
  root: StaticDataTable
  requires:
      - TableSchemasCreated
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      match ancestry.static_data_table(root.clone()).unwrap().setup {
          crate::storage_setup::StorageSetup::ReplicationStorageSetup(_) => true,
          _ => false,
      }
---
type: Constraint
spec:
  name: AllAssetsComputed
  root: Universe
  requires:
    - HistogramsComputed
    - Replicated
    - ComputeFilter
    - SVMRegressionModelsTrained
    - ConvertPredictionsCSVTableToORCTable
---
type: Constraint
spec:
  name: TableSchemasCreated
  root: HiveTableStorage
  requiresProgram: true
  requires:
    - TableSchemasDroppedIfExisting
  title: Creating Table Schemas
  body: |
      We will be uploading tabular data into our warehouse. Before we upload
      data files we need to create schemas for the tables which will refer
      to these files.
---
type: Constraint
spec:
  name: TableSchemasDroppedIfExisting
  root: HiveTableStorage
  requiresProgram: true
  requires:
    - HiveDirectoriesCreated
  title: Drop table schemas if they already exist.
  body: |
      Beware! Our workflow will overwrite any existing table schemas with the same
      name as our data.
---
type: Constraint
spec:
  name: CSVTableSchemasCreated
  root: HiveTableStorage
  requiresProgram: true
  requires:
    - HiveDirectoriesCreated
    - UploadDataToLocal
  title: Create schemas for temporary CSV tables.
  body: |
      We will use Hive tables with external storage as a staging location for our
      data. We need to create these schemas to be able to write data to them.
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      match ancestry.static_data_table(root.clone()) {
          Ok(sdt) => match &sdt.setup {
              crate::storage_setup::StorageSetup::ReplicationStorageSetup(_) => true,
              crate::storage_setup::StorageSetup::ComputedFromLocalData(cfld) => match &cfld.target {
                crate::storage::Storage::HiveTableStorage(hts) => match hts.encoding {
                  crate::encoding::Encoding::ORCEncoding(_) => {
                    let data_set = ancestry.data_set(root.clone()).unwrap();
                    let template = data_set.get_template_for_asset(sdt);
                    match template {
                      Ok(crate::template::DatumTemplate::PredictionsFromTrainedFloatMeasure(_)) => true,
                        Ok(_) => false,
                        Err(err) => panic!(err),
                    }
                  },
                  _ => false,
                }
                _ => false,
              },
              _ => false,
          },
          _ => false,
      }
---
type: Constraint
spec:
  name: HiveDirectoriesCreated
  root: OnPremiseLocation
  requiresProgram: true
  title: Created hive directories.
  body: |
      We need to create directories or buckets (depending on file system / storage
      solution) in which we will store our Hive data.
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
          ancestry.hive_table_storage(root.clone()).is_ok()
---
type: Constraint
spec:
  name: HistogramsComputed
  root: StaticDataTable
  requiresProgram: true
  requires:
    - Replicated
  title: Computing aggregations
  body: |
      We compute a few aggregations on the source data.
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>| {
          use crate::dataset::TDataSet;
          use crate::template::DatumTemplate;
          use crate::schema::DataSchema;

          let dataset = ancestry.data_set(root.clone()).unwrap();
          let root_tbl = ancestry.static_data_table(root.clone()).unwrap();
          let schema = &root_tbl.schema;
          let DataSchema::TabularSchema(ref tbl_schema) = schema;
          let template_name = tbl_schema.datumTemplateName.clone();
          /*println!("Template name: {}", template_name);
          for k in dataset.get_mapped_datum_templates().keys() {
            println!("template: {}", k);
          }*/
          match
          dataset.get_mapped_datum_templates().get(&template_name).unwrap() {
             DatumTemplate::IntegerMeasure(_) => true,
             _ => false
          }
      }
---
type: Constraint
spec:
  name: IsAuditedTable
  root: StaticDataTable
  requires:
    - Replicated
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      match ancestry.static_data_table(root.clone()).unwrap().setup {
          crate::storage_setup::StorageSetup::ReplicationStorageSetup(_) => true,
          _ => false,
      }
---
type: Constraint
spec:
  name: IsAudited
  root: Universe
  requires:
    - IsAuditedTable
---
type: Constraint
spec:
  name: ReplicatedData
  root: ReplicationStorageSetup
  requires:
    - UploadDataToLocal
    - FileReadyForUpload
---
type: Constraint
spec:
  name: FileReadyForUpload
  root: ReplicationStorageSetup
  requires:
    - RemoveFileHeader
    - DownloadDataFromRemote
---
type: Constraint
spec:
  name: DownloadDataFromRemote
  root: RemoteStorage
  requires:
    - DownloadDataFromRemoteGCSLocation
    - DownloadDataFromRemoteWebLocation
    - DownloadDataFromRemotePushshiftAPILocation
---
type: Constraint
spec:
  name: DownloadDataFromRemoteGCSLocation
  root: GCSLocation
  requiresProgram: true
  title: Downloading data from GCS
  body: |
      Data for this particular asset(s) is located in Google Cloud Storage.
      We need to download it to a local directory first, before we can
      do anything with it.
---
type: Constraint
spec:
  name: DownloadDataFromRemotePushshiftAPILocation
  root: PushshiftAPILocation
  requiresProgram: true
  title: Downloading data from the Pushshift API
  body: |
      Data for this particular asset(s) is located in the Pushshift API.
      We need to download it to a local directory first, before we can
      do anything with it.
---
type: Constraint
spec:
  name: DownloadDataFromRemoteWebLocation
  root: WebLocation
  requiresProgram: true
  title: Downloading data from remote web location
  body: |
      Data for this particular asset(s) is located somewhere on the web.
      We need to download it to a local directory first, before we can
      do anything with it.
---
type: Constraint
spec:
  name: RemoveFileHeader
  root: FileHeader
  requiresProgram: true
  requires:
    - FileIsDecompressed
    - DownloadDataFromRemote
  title: Removing file header
  body: |
      We are dealing with a tabular file with a header. Before we can
      process it we need to remove the header.
---
type: Constraint
spec:
  name: FileIsDecompressed
  root: RemoteStorage
  requires:
    - Decompress
---
type: Constraint
spec:
  name: Decompress
  root: DataCompression
  requires:
    - DecompressGzip
    - DecompressZip
---
type: Constraint
spec:
  name: DecompressGzip
  root: GzipCompression
  requiresProgram: true
  requires:
    - DownloadDataFromRemote
  title: Decompressing Gzip file
  body: |
      Data for this particular asset(s) is compressed with the GZIP
      algorith. Before we can process it further we need to decompress it.
---
type: Constraint
spec:
  name: DecompressZip
  root: ZipCompression
  requiresProgram: true
  requires:
    - DownloadDataFromRemote
  title: Decompressing Zipped file
  body: |
      Data for this particular asset(s) is compressed with the Zip
      algorith. Before we can process it further we need to decompress it.
---
type: Constraint
spec:
  name: UploadDataToLocal
  root: OnPremiseLocation
  requires:
      - UploadDataToAlluxio
      - UploadDataToMinio
      - UploadDataToSQLite
      - UploadDataToPostgres
      - UploadDataToBigQuery
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      ancestry.replication_storage_setup(root.clone()).is_ok()
---
type: Constraint
spec:
  name: UploadDataToAlluxio
  root: AlluxioLocation
  requiresProgram: true
  requires:
    - CSVIsConverted
    - ReplicatedSchema
  title: Upload data to Alluxio
  body: |
      Now that data has been pre-processed we can upload it to the underlying
      Alluxio storage.
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      ancestry.replication_storage_setup(root.clone()).is_ok()
---
type: Constraint
spec:
  name: UploadDataToMinio
  root: MinioLocation
  requiresProgram: true
  requires:
    - CSVIsConverted
    - ReplicatedSchema
  title: Upload data to Min.IO
  body: |
      Now that data has been pre-processed we can upload it to the underlying
      Min.IO storage.
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      ancestry.replication_storage_setup(root.clone()).is_ok()
---
type: Constraint
spec:
  name: UploadDataToSQLite
  root: SQLiteLocation
  requiresProgram: true
  requires:
    - CSVIsConverted
  title: Upload data to SQLite
  body: |
      Now that data has been converted to a CSV we can upload it to SQLite.
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      ancestry.replication_storage_setup(root.clone()).is_ok()
---
type: Constraint
spec:
  name: UploadDataToPostgres
  root: PostgresLocation
  requiresProgram: true
  requires:
    - CSVIsConverted
  title: Upload data to Postgres
  body: |
      Now that data has been converted to a CSV we can upload it to Postgres.
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      ancestry.replication_storage_setup(root.clone()).is_ok()
---
type: Constraint
spec:
  name: UploadDataToBigQuery
  root: BigQueryLocation
  requiresProgram: true
  requires:
    - CSVIsConverted
  title: Upload data to BigQuery
  body: |
      Now that data has been converted to a CSV we can upload it to BigQuery.
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      ancestry.replication_storage_setup(root.clone()).is_ok()
---
type: Constraint
spec:
  name: CSVIsConverted
  root: StaticDataTable
  requires:
    - ConvertToCSV
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      match ancestry.static_data_table(root.clone()).unwrap().setup {
          crate::storage_setup::StorageSetup::ReplicationStorageSetup(_) => true,
          _ => false,
      }
---
type: Constraint
spec:
  name: ConvertToCSV
  root: RemoteStorage
  requiresProgram: true
  requires:
    - RemoveFileHeader
    - DownloadDataFromRemote
  title: Convert data to CSV
  body: |
      We need to convert the data to CSV format to process it further (or if
      the data is already in CSV format, we will need to rename files accordingly).
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      ancestry.replication_storage_setup(root.clone()).is_ok()
---
type: Constraint
spec:
  name: ConvertPredictionsCSVTableToORCTable
  root: HiveTableStorage
  requires:
    - ComputePredictions
  requiresProgram: true
  title: Convert CSV Table to ORC Table
  body: |
      Hive tables can be stored in external CSV format, but this is inefficient.
      We can convert them to ORC (the native Hive format) to speed up access.
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      match ancestry.static_data_table(root.clone()) {
          Ok(sdt) => match &sdt.setup {
              crate::storage_setup::StorageSetup::ComputedFromLocalData(cfld) => match &cfld.target {
                crate::storage::Storage::HiveTableStorage(hts) => match hts.encoding {
                  crate::encoding::Encoding::ORCEncoding(_) => {
                    let data_set = ancestry.data_set(root.clone()).unwrap();
                    let template = data_set.get_template_for_asset(sdt);
                    match template {
                      Ok(crate::template::DatumTemplate::PredictionsFromTrainedFloatMeasure(_)) => true,
                        Ok(_) => false,
                        Err(err) => panic!(err),
                    }
                  },
                  _ => false,
                }
                _ => false,
              },
              _ => false,
          },
          _ => false,
      }
---
type: Constraint
spec:
  name: ConvertCSVTableToORCTable
  root: HiveTableStorage
  requires:
    - CSVTableSchemasCreated
    - UploadDataToLocal
  requiresProgram: true
  title: Convert CSV Table to ORC Table
  body: |
      Hive tables can be stored in external CSV format, but this is inefficient.
      We can convert them to ORC (the native Hive format) to speed up access.
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      match ancestry.static_data_table(root.clone()) {
          Ok(sdt) => match &sdt.setup {
              crate::storage_setup::StorageSetup::ReplicationStorageSetup(_) => true,
              _ => false,
          },
          _ => false,
      }
---
type: Constraint
spec:
  name: DroppedCSVTable
  root: HiveTableStorage
  requires:
    - ConvertCSVTableToORCTable
  requiresProgram: true
  title: Drop CSV Table
  body: |
      After we've converted a CSV table to ORC the CSV table is no longer needed,
      so it can be dropped.
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      ancestry.replication_storage_setup(root.clone()).is_ok()
---
type: Constraint
spec:
  name: SVMRegressionModelsTrained
  root: SupervisedModel
  requiresProgram: true
  requires:
    - SourceAssetHasBeenComputed
  title: Training SVM Regression Models
  body: |
      Support Vector Machines are some of the simplest ML models possible.
      These are even supported by Trino!
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      match ancestry.supervised_model(root.clone()).unwrap().algorithm {
          crate::algorithms::RegressionAlgorithm::SVMRegressionAlgorithm(_) => true,
          _ => false,
      } &&
      match ancestry.supervised_model(root.clone()).unwrap().setup {
          crate::storage_setup::StorageSetup::ComputedFromLocalData(ref setup)
          => match &setup.target {
              crate::storage::Storage::LocalFileStorage(storage) =>
              match storage.location {
                  OnPremiseLocation::MinioLocation(_) => true,
                  _ => false,
              }
              _ => false,
          },
          _ => false,
      }
---
type: Constraint
spec:
  name: SourceAssetHasBeenComputed
  root: ComputedFromLocalData
  requires:
      - ReplicatedAssets
      - TableSchemasCreated
  requiredConstraintsClosure: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>| {
          let setup = ancestry.computed_from_local_data(root.clone()).unwrap();
          let dataset = ancestry.data_set(root.clone()).unwrap();
          let uuids: Vec<_> = dataset.get_source_assets(&setup).unwrap().values().map(|x| x.get_uuid().clone()).collect();
          if uuids.len() == 0 {
              panic!(format!(
                  "Cannot find source asset with names {}",
                  setup.source_asset_names.values().map(|x| x.clone()).collect::<Vec<String>>().join(",")
              ));
          }
          uuids
      }
---
type: Constraint
spec:
  name: ComputeFilter
  requiresProgram: true
  root: ComputedFromLocalData
  requires:
      - SourceAssetHasBeenComputed
      - ReplicatedAssets
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>| {
          use crate::template::DatumTemplate;
          use crate::schema::DataSchema;
          use crate::dataset::TDataSet;

          let maybe_derived_asset = ancestry.derived_asset(root.clone());
          if let Ok(derived_asset) = maybe_derived_asset {
            let data_set = ancestry.data_set(root.clone()).unwrap();
            let DataSchema::TabularSchema(ref t) = derived_asset.schema;
            let mapped_templates = data_set.get_mapped_datum_templates();
            let template = mapped_templates.get(&t.datumTemplateName);
            return match template {
                Some(DatumTemplate::Filter(_)) => true,
                _ => false
            };
          }
          false
      }
  requiredConstraintsClosure: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>| {
          let setup = ancestry.computed_from_local_data(root.clone()).unwrap();
          let dataset = ancestry.data_set(root.clone()).unwrap();
          let uuids: Vec<_> = dataset.get_source_assets(&setup).unwrap().values().map(|x| x.get_uuid().clone()).collect();
          if uuids.len() == 0 {
              panic!(format!(
                  "Cannot find source asset with names {}",
                  setup.source_asset_names.values().map(|x| x.clone()).collect::<Vec<String>>().join(",")
              ));
          }
          uuids
      }
---
type: Constraint
spec:
  name: ComputePredictions
  root: ComputedFromLocalData
  requiresProgram: true
  requires:
      - SVMRegressionModelsTrained
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>| {
          use crate::template::DatumTemplate;
          use crate::schema::DataSchema;
          use crate::dataset::TDataSet;

          let maybe_static_data_table = ancestry.static_data_table(root.clone());
          if let Ok(static_data_table) = maybe_static_data_table {
            let data_set = ancestry.data_set(root.clone()).unwrap();
            let DataSchema::TabularSchema(ref t) = static_data_table.schema;
            let mapped_templates = data_set.get_mapped_datum_templates();
            let template = mapped_templates.get(&t.datumTemplateName);
            return match template {
                Some(DatumTemplate::PredictionsFromTrainedFloatMeasure(_)) => true,
                None => panic!(format!("Could not find datum template: {}", t.datumTemplateName)),
                _ => false,
            };
          }
          false
      }
  requiredConstraintsClosure: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>| {
          let setup = ancestry.computed_from_local_data(root.clone()).unwrap();
          let dataset = ancestry.data_set(root.clone()).unwrap();
          let uuids: Vec<_> = dataset.get_source_assets(&setup).unwrap().values().map(|x| x.get_uuid().clone()).collect();
          if uuids.len() == 0 {
              panic!(format!(
                  "Cannot find source asset with names {}",
                  setup.source_asset_names.values().map(|x| x.clone()).collect::<Vec<String>>().join(",")
              ));
          }
          uuids
      }

