---
type: Constraint
spec:
  name: Replicated
  root: Universe
  requires:
    - ReplicatedDataSets
---
type: Constraint
spec:
  name: ReplicatedDataSets
  root: DataSet
  requires:
    - ReplicatedAssets
---
type: Constraint
spec:
  name: ReplicatedAssets
  root: Asset
  requires:
    - ReplicatedSchema
    - DroppedCSVTable
    - TableSchemasCreated
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>| {
        use crate::storage_setup::*;
        if let StorageSetup::RemoteImportStorageSetup(_) = ancestry.asset(root.clone()).unwrap().get_storage_setup() {
          return true;
        }
        false
      }
---
type: Constraint
spec:
  name: ReplicatedSchema
  root: StaticDataTable
  requires:
      - TableSchemasCreated
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      match ancestry.static_data_table(root.clone()).unwrap().setup {
          crate::storage_setup::StorageSetup::RemoteImportStorageSetup(_) => true,
          _ => false,
      }
---
type: Constraint
spec:
  name: DataDownloadedAndConverted
  root: Universe
  requires:
    - HistogramsComputed
    - SVMRegressionModelsTrained
    - Replicated
---
type: Constraint
spec:
  name: TableSchemasCreated
  root: HiveTableStorage
  requiresProgram: true
  requires:
    - TableSchemasDroppedIfExisting
  title: Creating Table Schemas
  body: |
      We will be uploading tabular data into our warehouse. Before we upload
      data files we need to create schemas for the tables which will refer
      to these files.
---
type: Constraint
spec:
  name: TableSchemasDroppedIfExisting
  root: HiveTableStorage
  requiresProgram: true
  requires:
    - HiveDirectoriesCreated
  title: Drop table schemas if they already exist.
  body: |
      Beware! Our workflow will overwrite any existing table schemas with the same
      name as our data.
---
type: Constraint
spec:
  name: CSVTableSchemasCreated
  root: HiveTableStorage
  requiresProgram: true
  requires:
    - HiveDirectoriesCreated
    - UploadDataToLocal
  title: Create schemas for temporary CSV tables.
  body: |
      We will use Hive tables with external storage as a staging location for our
      data. We need to create these schemas to be able to write data to them.
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      match ancestry.static_data_table(root.clone()) {
          Ok(sdt) => match sdt.setup {
              crate::storage_setup::StorageSetup::RemoteImportStorageSetup(_) => true,
              _ => false,
          },
          _ => false,
      }
---
type: Constraint
spec:
  name: HiveDirectoriesCreated
  root: HiveLocation
  requiresProgram: true
  title: Created hive directories.
  body: |
      We need to create directories or buckets (depending on file system / storage
      solution) in which we will store our Hive data.
---
type: Constraint
spec:
  name: HistogramsComputed
  root: StaticDataTable
  requiresProgram: true
  requires:
    - Replicated
  title: Computing aggregations
  body: |
      We compute a few aggregations on the source data.
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>| {
          use crate::dataset::TDataSet;
          use crate::template::DatumTemplate;
          use crate::schema::DataSchema;

          let dataset = ancestry.data_set(root.clone()).unwrap();
          let root_tbl = ancestry.static_data_table(root.clone()).unwrap();
          let schema = &root_tbl.schema;
          let DataSchema::TabularSchema(ref tbl_schema) = schema;
          let template_name = tbl_schema.datumTemplateName.clone();
          /*println!("Template name: {}", template_name);
          for k in dataset.get_mapped_datum_templates().keys() {
            println!("template: {}", k);
          }*/
          match
          dataset.get_mapped_datum_templates().get(&template_name).unwrap() {
             DatumTemplate::IntegerMeasure(_) => true,
             _ => false
          }
      }
---
type: Constraint
spec:
  name: IsAuditedTable
  root: StaticDataTable
  requires:
    - Replicated
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      match ancestry.static_data_table(root.clone()).unwrap().setup {
          crate::storage_setup::StorageSetup::RemoteImportStorageSetup(_) => true,
          _ => false,
      }
---
type: Constraint
spec:
  name: IsAudited
  root: Universe
  requires:
    - IsAuditedTable
---
type: Constraint
spec:
  name: ReplicatedData
  root: RemoteImportStorageSetup
  requires:
    - UploadDataToLocal
    - FileReadyForUpload
---
type: Constraint
spec:
  name: FileReadyForUpload
  root: RemoteImportStorageSetup
  requires:
    - RemoveFileHeader
    - DownloadDataFromRemote
---
type: Constraint
spec:
  name: DownloadDataFromRemote
  root: RemoteStorage
  requires:
    - DownloadDataFromRemoteGCSLocation
    - DownloadDataFromRemoteWebLocation
---
type: Constraint
spec:
  name: DownloadDataFromRemoteGCSLocation
  root: GCSLocation
  requiresProgram: true
  title: Downloading data from GCS
  body: |
      Data for this particular asset(s) is located in Google Cloud Storage.
      We need to download it to a local directory first, before we can
      do anything with it.
---
type: Constraint
spec:
  name: DownloadDataFromRemoteWebLocation
  root: WebLocation
  requiresProgram: true
  title: Downloading data from remote web location
  body: |
      Data for this particular asset(s) is located somewhere on the web.
      We need to download it to a local directory first, before we can
      do anything with it.
---
type: Constraint
spec:
  name: RemoveFileHeader
  root: FileHeader
  requiresProgram: true
  requires:
    - FileIsDecompressed
  title: Removing file header
  body: |
      We are dealing with a tabular file with a header. Before we can
      process it we need to remove the header.
---
type: Constraint
spec:
  name: FileIsDecompressed
  root: RemoteStorage
  requires:
    - Decompress
---
type: Constraint
spec:
  name: Decompress
  root: DataCompression
  requires:
    - DecompressGzip
    - DecompressZip
---
type: Constraint
spec:
  name: DecompressGzip
  root: GzipCompression
  requiresProgram: true
  requires:
    - DownloadDataFromRemote
  title: Decompressing Gzip file
  body: |
      Data for this particular asset(s) is compressed with the GZIP
      algorith. Before we can process it further we need to decompress it.
---
type: Constraint
spec:
  name: DecompressZip
  root: ZipCompression
  requiresProgram: true
  requires:
    - DownloadDataFromRemote
  title: Decompressing Zipped file
  body: |
      Data for this particular asset(s) is compressed with the Zip
      algorith. Before we can process it further we need to decompress it.
---
type: Constraint
spec:
  name: UploadDataToLocal
  root: HiveLocation
  requires:
      - UploadDataToAlluxio
      - UploadDataToMinio
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      ancestry.remote_import_storage_setup(root.clone()).is_ok()
---
type: Constraint
spec:
  name: UploadDataToAlluxio
  root: AlluxioLocation
  requiresProgram: true
  requires:
    - CSVIsConverted
    - ReplicatedSchema
  title: Upload data to Alluxio
  body: |
      Now that data has been pre-processed we can upload it to the underlying
      Alluxio storage.
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      ancestry.remote_import_storage_setup(root.clone()).is_ok()
---
type: Constraint
spec:
  name: UploadDataToMinio
  root: MinioLocation
  requiresProgram: true
  requires:
    - CSVIsConverted
    - ReplicatedSchema
  title: Upload data to Min.IO
  body: |
      Now that data has been pre-processed we can upload it to the underlying
      Alluxio storage.
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      ancestry.remote_import_storage_setup(root.clone()).is_ok()
---
type: Constraint
spec:
  name: CSVIsConverted
  root: StaticDataTable
  requires:
    - ConvertToCSV
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      match ancestry.static_data_table(root.clone()).unwrap().setup {
          crate::storage_setup::StorageSetup::RemoteImportStorageSetup(_) => true,
          _ => false,
      }
---
type: Constraint
spec:
  name: ConvertToCSV
  root: RemoteStorage
  requiresProgram: true
  requires:
    - RemoveFileHeader
    - DownloadDataFromRemote
  title: Convert data to CSV
  body: |
      We need to convert the data to CSV format to process it further (or if
      the data is already in CSV format, we will need to rename files accordingly).
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      ancestry.remote_import_storage_setup(root.clone()).is_ok()
---
type: Constraint
spec:
  name: ConvertCSVTableToORCTable
  root: HiveTableStorage
  requires:
    - CSVTableSchemasCreated
  requiresProgram: true
  title: Convert CSV Table to ORC Table
  body: |
      Hive tables can be stored in external CSV format, but this is inefficient.
      We can convert them to ORC (the native Hive format) to speed up access.
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      ancestry.remote_import_storage_setup(root.clone()).is_ok()
---
type: Constraint
spec:
  name: DroppedCSVTable
  root: HiveTableStorage
  requires:
    - ConvertCSVTableToORCTable
  requiresProgram: true
  title: Drop CSV Table
  body: |
      After we've converted a CSV table to ORC the CSV table is no longer needed,
      so it can be dropped.
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      ancestry.remote_import_storage_setup(root.clone()).is_ok()
---
type: Constraint
spec:
  name: SVMRegressionModelsTrained
  root: SupervisedModel
  requiresProgram: true
  requires:
    - SourceAssetHasBeenComputed
  title: Training SVM Regression Models
  body: |
      Support Vector Machines are some of the simplest ML models possible.
      These are even supported by Trino!
  attachIf: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>|
      match ancestry.supervised_model(root.clone()).unwrap().algorithm {
          crate::algorithms::RegressionAlgorithm::SVMRegressionAlgorithm(_) => true,
          _ => false,
      }
---
type: Constraint
spec:
  name: SourceAssetHasBeenComputed
  root: ComputedFromLocalData
  requires:
      - ReplicatedAssets
      - TableSchemasCreated
  requiredConstraintsClosure: |
      |root: Concept<'a>, ancestry: &ConceptAncestry<'a>| {
          let setup = ancestry.computed_from_local_data(root.clone()).unwrap();
          let dataset = ancestry.data_set(root.clone()).unwrap();
          let source_asset = dataset.assets.iter().filter(|x| x.get_name() == setup.source_asset_name).next().unwrap();
          vec![source_asset.get_uuid().clone()]
      }
