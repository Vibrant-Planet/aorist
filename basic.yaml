type: Attribute
spec:
  name: KeyStringIdentifier
  orc: OrcString
  presto: PrestoVarchar
  sql: SQLVarchar
---
type: Attribute
spec:
  name: KeyInt64Identifier
  orc: OrcBigint
  presto: PrestoBigint
  sql: SQLBigint
---
type: Attribute
spec:
  name: Empty
  orc: OrcString
  presto: PrestoVarchar
  sql: SQLVarchar
---
type: Attribute
spec:
  name: NumericIdentifier
  orc: OrcBigint
  presto: PrestoBigint
  sql: SQLBigint
---
type: Attribute
spec:
  name: NullableStringIdentifier
  orc: OrcString
  presto: PrestoVarchar
  sql: SQLVarchar
---
type: Attribute
spec:
  name: NullablePOSIXTimestamp
  orc: OrcBigint
  presto: PrestoBigint
  sql: SQLBigint
---
type: Attribute
spec:
  name: NullableInt64
  orc: OrcBigint
  presto: PrestoBigint
  sql: SQLBigint
---
type: Attribute
spec:
  name: Int64Identifier
  orc: OrcBigint
  presto: PrestoBigint
  sql: SQLBigint
---
type: Attribute
spec:
  name: NullableString
  orc: OrcString
  presto: PrestoVarchar
  sql: SQLVarchar
---
type: Attribute
spec:
  name: FloatLatitude
  orc: OrcFloat
  presto: PrestoReal
  sql: SQLReal
---
type: Attribute
spec:
  name: FloatLongitude
  orc: OrcFloat
  presto: PrestoReal
  sql: SQLReal
---
type: Attribute
spec:
  name: URI
  orc: OrcString
  presto: PrestoVarchar
  sql: SQLVarchar
---
type: Constraint
spec:
  name: Replicated
  root: Universe
  requires:
    - ReplicatedDataSets
---
type: Constraint
spec:
  name: ReplicatedDataSets
  root: DataSet
  requires:
    - ReplicatedAssets
---
type: Constraint
spec:
  name: ReplicatedAssets
  root: Asset
  requires:
    - ReplicatedSchema
---
type: Constraint
spec:
  name: ReplicatedSchema
  root: StaticDataTable
  requires:
      - TableSchemasCreated
---
type: Constraint
spec:
  name: Test
  root: Universe
  requires:
    - UploadDataToLocal
---
type: Constraint
spec:
  name: TableSchemasCreated
  root: HiveTableStorage
  requiresProgram: true
  requires:
    - HiveDirectoriesCreated
---
type: Constraint
spec:
  name: HiveDirectoriesCreated
  root: AlluxioLocation
  requiresProgram: true
---
type: Constraint
spec:
  name: IsAuditedTable
  root: StaticDataTable
  requires:
    - Replicated
---
type: Constraint
spec:
  name: IsAudited
  root: Universe
  requires:
    - IsAuditedTable
---
type: Constraint
spec:
  name: ReplicatedData
  root: RemoteImportStorageSetup
  requires:
    - UploadDataToLocal
    - FileReadyForUpload
---
type: Constraint
spec:
  name: FileReadyForUpload
  root: RemoteImportStorageSetup
  requires:
    - RemoveFileHeader
---
type: Constraint
spec:
  name: DownloadDataFromRemote
  root: RemoteStorage
  requires:
    - DownloadDataFromRemoteGCSLocation
    - DownloadDataFromRemoteWebLocation
---
type: Constraint
spec:
  name: DownloadDataFromRemoteGCSLocation
  root: GCSLocation
  requiresProgram: true
---
type: Constraint
spec:
  name: DownloadDataFromRemoteWebLocation
  root: WebLocation
  requiresProgram: true
---
type: Constraint
spec:
  name: RemoveFileHeader
  root: FileHeader
  requiresProgram: true
  requires:
    - FileIsDecompressed
---
type: Constraint
spec:
  name: FileIsDecompressed
  root: RemoteStorage
  requires:
    - Decompress
---
type: Constraint
spec:
  name: Decompress
  root: DataCompression
  requires:
    - DecompressGzip
    - DecompressZip
---
type: Constraint
spec:
  name: DecompressGzip
  root: GzipCompression
  requiresProgram: true
  requires:
    - DownloadDataFromRemote
---
type: Constraint
spec:
  name: DecompressZip
  root: ZipCompression
  requiresProgram: true
  requires:
    - DownloadDataFromRemote
---
type: Constraint
spec:
  name: ConvertCSVToOrc
  root: RemoteImportStorageSetup
  requiresProgram: true
---
type: Constraint
spec:
  name: ConvertCSVToOrc2
  root: RemoteImportStorageSetup
  requires:
      - FileReadyForUpload
  requiresProgram: true
---
type: Constraint
spec:
  name: UploadDataToLocal
  root: HiveLocation
  requires:
      - UploadDataToAlluxio
---
type: Constraint
spec:
  name: UploadDataToAlluxio
  root: AlluxioLocation
  requiresProgram: true
  requires:
    - FileReadyForUpload
    - ReplicatedSchema
---
type: Program
spec:
  use: UploadDataToAlluxio
  root: AlluxioLocation
  dialect: Python
  preamble: |
    import alluxio
    from alluxio import option

    def upload_to_alluxio(hostname, port, schema, directory, tablename, tmp_dir, source_file):
      directory = '/' + schema + '/' + directory + '/' + tablename
      client = alluxio.Client(hostname, int(port))
      opt = option.CreateDirectory(recursive=True)
      client.create_directory(directory, opt)
      with client.open(directory + '/data.csv', 'w') as f:
        with open(tmp_dir + '/' + source_file) as source:
          f.write(source)
      print("Done uploading %s" % source_file)
  call: upload_to_alluxio
  args:
    - type: AncestorArgument
      spec:
        call: universe.endpoints.alluxio.as_ref().unwrap().server.clone()
        attaches: Universe
    - type: AncestorArgument
      spec:
        call: format!("{}", universe.endpoints.alluxio.as_ref().unwrap().apiPort).to_string()
        attaches: Universe
    - type: AncestorArgument
      spec:
        call: alluxio_location.schema
        attaches: AlluxioLocation
    - type: AncestorArgument
      spec:
        call: universe.endpoints.alluxio.as_ref().unwrap().directory.clone()
        attaches: Universe
    - type: AncestorArgument
      spec:
        call: format!("{}_csv", static_data_table.name).to_string()
        attaches: StaticDataTable
    - type: AncestorArgument
      spec:
        call: remote_import_storage_setup.tmp_dir
        attaches: RemoteImportStorageSetup
    - type: AncestorArgument
      spec:
        call: format!("{}.no_header", static_data_table.name).to_string()
        attaches: StaticDataTable
---
type: Program
spec:
  use: DownloadDataFromRemoteGCSLocation
  root: GCSLocation
  dialect: Python
  preamble: |
    from google.cloud import storage
    import os
    def download_blob_to_file(bucket_name, blob_name, tmp_dir, file_name):
      client = storage.Client.from_service_account_json('/home/bogdan/.gcloud/social_norms.json')
      if not os.path.exists(tmp_dir):
          os.makedirs(tmp_dir)
      bucket = client.bucket(bucket_name)
      blob = bucket.blob(blob_name)
      dest = "%s/%s" % (tmp_dir, file_name)
      blob.download_to_filename(dest)
  call: download_blob_to_file
  args:
    - type: AncestorArgument
      spec:
        call: gcs_location.bucket
        attaches: GCSLocation
    - type: AncestorArgument
      spec:
        call: gcs_location.blob
        attaches: GCSLocation
    - type: AncestorArgument
      spec:
        call: remote_import_storage_setup.tmp_dir
        attaches: RemoteImportStorageSetup
    - type: AncestorArgument
      spec:
        call: format!("{}.downloaded", static_data_table.name).to_string()
        attaches: StaticDataTable
---
type: Program
spec:
  use: DownloadDataFromRemoteWebLocation
  root: WebLocation
  dialect: Bash
  call: mkdir -p {tmp_dir} && curl {address} -o {tmp_dir}/{file_name}
  kwargs:
    address:
      type: AncestorArgument
      spec:
        call: web_location.address
        attaches: WebLocation
        name: address
    tmp_dir:
      type: AncestorArgument
      spec:
        call: remote_import_storage_setup.tmp_dir
        attaches: RemoteImportStorageSetup
        name: tmp_dir
    file_name:
      type: AncestorArgument
      spec:
        call: format!("{}.downloaded", static_data_table.name).to_string()
        attaches: StaticDataTable
        name: file_name
---
type: Program
spec:
  use: DecompressZip
  root: ZipCompression
  dialect: Bash
  call: unzip {command}
  kwargs:
    command:
      type: MultipleAncestorsArgument
      spec:
        name: command
        call: >
          match &zip_compression.filename {
            Some(ref file) => format!(
                "-p {tmp_dir}/{archive_name}.downloaded {file_name} > {tmp_dir}/{archive_name}.txt",
                tmp_dir=remote_import_storage_setup.tmp_dir,
                archive_name=static_data_table.name,
                file_name=file,
            ).to_string(),
            None => format!(
                "-p {tmp_dir}/{archive_name}.downloaded > {tmp_dir}/{archive_name}.txt",
                tmp_dir=remote_import_storage_setup.tmp_dir,
                archive_name=static_data_table.name,
            )
          }
        attaches:
          - ZipCompression
          - StaticDataTable
          - RemoteImportStorageSetup
---
type: Program
spec:
  use: DecompressGzip
  root: GzipCompression
  dialect: Bash
  call: gunzip {command}
  kwargs:
    command:
      type: MultipleAncestorsArgument
      spec:
        name: command
        call: >
            format!(
                "--suffix=downloaded -c {tmp_dir}/{archive_name}.downloaded > {tmp_dir}/{archive_name}.txt",
                tmp_dir=remote_import_storage_setup.tmp_dir,
                archive_name=static_data_table.name,
            )
        attaches:
          - StaticDataTable
          - RemoteImportStorageSetup
---
type: Program
spec:
  use: RemoveFileHeader
  root: FileHeader
  dialect: Bash
  call: |
    tail -n +{n} {tmp_dir}/{file_name}.txt > {tmp_dir}/{file_name}.no_header &&
    rm {tmp_dir}/{file_name}.txt
  kwargs:
    n:
      type: AncestorArgument
      spec:
        attaches: FileHeader
        call: format!("{}", file_header.get_num_lines() + 1)
    tmp_dir:
      type: AncestorArgument
      spec:
        call: remote_import_storage_setup.tmp_dir
        attaches: RemoteImportStorageSetup
        name: tmp_dir
    file_name:
      type: AncestorArgument
      spec:
        call: static_data_table.name
        attaches: StaticDataTable
        name: file_name
---
type: Program
spec:
  use: ConvertCSVToOrc
  root: RemoteImportStorageSetup
  dialect: Bash
  call: >
    csv-import {tmp_dir}/{table_name}.no_header
    {tmp_dir}/{table_name}.no_header
  kwargs:
    tmp_dir:
      type: AncestorArgument
      spec:
        call: remote_import_storage_setup.tmp_dir
        attaches: RemoteImportStorageSetup
    table_name:
      type: AncestorArgument
      spec:
        call: static_data_table.name
        attaches: StaticDataTable
    schema:
      type: MultipleAncestorsArgument
      spec:
        call: >
          {
            let DataSchema::TabularSchema(ref t) = static_data_table.schema;
            let attributes = t.attributes.clone();
            let attr_v = data_set
                .datumTemplates
                .iter()
                .filter(|x| {
                    x.get_name().clone() == t.datumTemplateName
                })
                .map(|x| match x {
                    DatumTemplate::KeyedStruct(k) => k.get_attributes(),
                    DatumTemplate::IdentifierTuple(t) => t.get_attributes(),
                })
                .next().unwrap();
            let attr_map = attr_v.iter()
                .map(|x| (x.get_name().clone(), x.get_orc_type()))
                .collect::<LinkedHashMap<String, String>>();
            let attr_types = attributes.iter().map(
                |x| format!(
                    "{}:{}",
                    x,
                    attr_map.get(x).unwrap().clone()
                ).to_string()
            ).collect::<Vec<String>>();
            attr_types.join(",")
          }
        attaches:
          - StaticDataTable
          - DataSet

---
type: Program
spec:
  use: HiveDirectoriesCreated
  root: AlluxioLocation
  dialect: Presto
  call: CREATE SCHEMA IF NOT EXISTS {presto_schema} WITH (location='{location}')
  kwargs:
    presto_schema:
      type: AncestorArgument
      spec:
        attaches: HiveLocation
        call: >
          match &hive_location {
            HiveLocation::AlluxioLocation(a) => a.schema.to_string(),
          }
    location:
      type: MultipleAncestorsArgument
      spec:
        attaches:
           - HiveTableStorage
           - Universe
        call: >
          match &hive_table_storage.location {
            HiveLocation::AlluxioLocation(a) => format!(
                "alluxio://{}:{}/{}/{}",
                universe.endpoints.alluxio.as_ref().unwrap().server,
                universe.endpoints.alluxio.as_ref().unwrap().rpcPort,
                universe.endpoints.alluxio.as_ref().unwrap().directory,
                a.schema
            ).to_string()
          }
---
type: Program
spec:
  use: TableSchemasCreated
  root: HiveTableStorage
  dialect: Presto
  call: CREATE TABLE IF NOT EXISTS {presto_schema}.{table_name} ({schema}) WITH (format='{data_format}')
  kwargs:
    table_name:
      type: AncestorArgument
      spec:
        call: static_data_table.name
        attaches: StaticDataTable
    data_format:
      type: AncestorArgument
      spec:
        call: >
          match &hive_table_storage.encoding {
            Encoding::ORCEncoding(_) => "ORC".to_string(),
            _ => panic!("Format not supported for hive table")
          }
        attaches: HiveTableStorage
    presto_schema:
      type: AncestorArgument
      spec:
        attaches: HiveTableStorage
        call: >
          match &hive_table_storage.location {
            HiveLocation::AlluxioLocation(a) => a.schema.to_string(),
          }
    schema:
      type: MultipleAncestorsArgument
      spec:
        call: >
          {
            use crate::attributes::TAttribute;
            let DataSchema::TabularSchema(ref t) = static_data_table.schema;
            let dictionary = Standard::from_embedded(Language::EnglishUS).unwrap();
            let options = Options::new(66).splitter(dictionary);

            let attr_v = data_set
                .datumTemplates
                .iter()
                .filter(|x| {
                    x.get_name().clone() == t.datumTemplateName
                })
                .map(|x| match x {
                    DatumTemplate::KeyedStruct(k) => k.get_attributes(),
                    DatumTemplate::IdentifierTuple(t) => t.get_attributes(),
                })
                .next().unwrap();
            let attr_map = attr_v.iter()
                .map(|x|
                    (x.get_name().clone(), (x.get_presto_type(), x.get_comment().clone())))
                .collect::<Vec<_>>();
            let attr_types = attr_map.iter().map(|x| {
                let (name, (presto_type, comment)) = x;
                let comment_str = match comment {
                    Some(c) => {
                        let cleaned_up_comment = c
                          .split("\n")
                          .into_iter()
                          .map(|x| x.to_string().trim().to_string())
                          .collect::<Vec<String>>().join(" ");
                        fill(cleaned_up_comment.trim(), &options)
                          .split("\n").map(|x| x.to_string()).collect::<Vec<String>>()
                    }
                    None => vec!["".to_string()],
                };
                if comment_str.len() == 1 {
                    return format!(
                        "    {} {} COMMENT '{}'",
                        name,
                        presto_type,
                        comment_str.get(0).unwrap().to_string().replace("\'", "`"),
                    ).to_string();
                } else {
                    return format!(
                        "    {} {} \n COMMENT {}\n",
                        name,
                        presto_type,
                        comment_str
                          .into_iter()
                          .map(|x| format!("        '{}'", x.to_string().replace("\'", "`")).to_string())
                          .collect::<Vec<String>>().join("\n")
                    ).to_string();
                }
            }).collect::<Vec<String>>();
            format!("{}\n", attr_types.join(",\n"))
          }
        attaches:
          - StaticDataTable
          - DataSet
