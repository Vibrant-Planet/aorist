---
type: Program
spec:
  use: UploadDataToAlluxio
  root: AlluxioLocation
  dialect: Python
  preamble: |
    import alluxio
    from alluxio import option, wire
    def upload_to_alluxio(hostname, port, schema, directory, tablename, tmp_dir, source_file):
      directory = '/' + directory + '/' + schema + '/' + tablename
      client = alluxio.Client(hostname, int(port))
      opt = option.CreateDirectory(recursive=True, allow_exists=True, write_type=wire.WRITE_TYPE_MUST_CACHE)
      client.create_directory(directory, opt)
      path = directory + "/data.csv"
      if client.exists(path):
        client.delete(path)
      opt = option.CreateFile(write_type=wire.WRITE_TYPE_MUST_CACHE)
      with client.open(path, 'w', opt) as f:
        with open(tmp_dir + '/' + source_file) as source:
          try:
            f.write(source)
          except:
            pass
      print("Done uploading %s to %s" % (source_file, path))
  call: upload_to_alluxio
  args:
    - type: AncestorArgument
      spec:
        call: universe.endpoints.alluxio.as_ref().unwrap().server.clone()
        attaches: Universe
    - type: AncestorArgument
      spec:
        call: format!("{}", universe.endpoints.alluxio.as_ref().unwrap().apiPort).to_string()
        attaches: Universe
    - type: AncestorArgument
      spec:
        call: data_set.name
        attaches: DataSet
    - type: AncestorArgument
      spec:
        call: universe.endpoints.alluxio.as_ref().unwrap().directory.clone()
        attaches: Universe
    - type: AncestorArgument
      spec:
        call: format!("{}_csv", static_data_table.name).to_string()
        attaches: StaticDataTable
    - type: AncestorArgument
      spec:
        call: remote_import_storage_setup.tmp_dir
        attaches: RemoteImportStorageSetup
    - type: AncestorArgument
      spec:
        call: format!("{}.csv", static_data_table.name).to_string()
        attaches: StaticDataTable
---
type: Program
spec:
  use: UploadDataToMinio
  root: MinioLocation
  dialect: Python
  preamble: |
    from minio import Minio
    def upload_to_minio(hostname, port, access_key, secret_key, bucket, schema, tablename, tmp_dir, source_file):
        client = Minio(
            "%s:%s" % (hostname, port),
            access_key=access_key,
            secret_key=secret_key,
            secure=False,
        )

        assert client.bucket_exists(bucket)
        dest_path = schema + '/' + tablename + '/data.csv'
        source_path = tmp_dir + "/" + source_file
        client.fput_object(bucket, dest_path, source_path)
        print("Successfully uploaded %s to %s" % (source_path, dest_path))
  call: upload_to_minio
  args:
    - type: AncestorArgument
      spec:
        call: universe.endpoints.minio.as_ref().unwrap().server
        attaches: Universe
    - type: AncestorArgument
      spec:
        call: universe.endpoints.minio.as_ref().unwrap().port.to_string()
        attaches: Universe
    - type: AncestorArgument
      spec:
        call: universe.endpoints.minio.as_ref().unwrap().access_key
        attaches: Universe
    - type: AncestorArgument
      spec:
        call: universe.endpoints.minio.as_ref().unwrap().secret_key
        attaches: Universe
    - type: AncestorArgument
      spec:
        call: universe.endpoints.minio.as_ref().unwrap().bucket
        attaches: Universe
    - type: AncestorArgument
      spec:
        call: data_set.name
        attaches: DataSet
    - type: AncestorArgument
      spec:
        call: format!("{}_csv", static_data_table.name).to_string()
        attaches: StaticDataTable
    - type: AncestorArgument
      spec:
        call: remote_import_storage_setup.tmp_dir
        attaches: RemoteImportStorageSetup
    - type: AncestorArgument
      spec:
        call: format!("{}.csv", static_data_table.name).to_string()
        attaches: StaticDataTable
---
type: Program
spec:
  use: DownloadDataFromRemoteGCSLocation
  root: GCSLocation
  dialect: Python
  preamble: |
    from google.cloud import storage
    import os
    def download_blob_to_file(bucket_name, blob_name, tmp_dir, file_name):
      client = storage.Client.from_service_account_json('/home/bogdan/.gcloud/social_norms.json')
      if not os.path.exists(tmp_dir):
          os.makedirs(tmp_dir)
      bucket = client.bucket(bucket_name)
      blob = bucket.blob(blob_name)
      dest = "%s/%s" % (tmp_dir, file_name)
      blob.download_to_filename(dest)
  call: download_blob_to_file
  args:
    - type: AncestorArgument
      spec:
        call: gcs_location.bucket
        attaches: GCSLocation
    - type: AncestorArgument
      spec:
        call: gcs_location.blob
        attaches: GCSLocation
    - type: AncestorArgument
      spec:
        call: remote_import_storage_setup.tmp_dir
        attaches: RemoteImportStorageSetup
    - type: AncestorArgument
      spec:
        call: format!("{}.downloaded", static_data_table.name).to_string()
        attaches: StaticDataTable
---
type: Program
spec:
  use: DownloadDataFromRemoteWebLocation
  root: WebLocation
  dialect: Bash
  call: mkdir -p {tmp_dir} && curl {address} -o {tmp_dir}/{file_name}
  kwargs:
    address:
      type: AncestorArgument
      spec:
        call: web_location.address
        attaches: WebLocation
        name: address
    tmp_dir:
      type: AncestorArgument
      spec:
        call: remote_import_storage_setup.tmp_dir
        attaches: RemoteImportStorageSetup
        name: tmp_dir
    file_name:
      type: AncestorArgument
      spec:
        call: format!("{}.downloaded", static_data_table.name).to_string()
        attaches: StaticDataTable
        name: file_name
---
type: Program
spec:
  use: DecompressZip
  root: ZipCompression
  dialect: Bash
  call: unzip {command}
  kwargs:
    command:
      type: MultipleAncestorsArgument
      spec:
        name: command
        call: >
          match &zip_compression.filename {
            Some(ref file) => format!(
                "-p {tmp_dir}/{archive_name}.downloaded {file_name} > {tmp_dir}/{archive_name}.txt",
                tmp_dir=remote_import_storage_setup.tmp_dir,
                archive_name=static_data_table.name,
                file_name=file,
            ).to_string(),
            None => format!(
                "-p {tmp_dir}/{archive_name}.downloaded > {tmp_dir}/{archive_name}.txt",
                tmp_dir=remote_import_storage_setup.tmp_dir,
                archive_name=static_data_table.name,
            )
          }
        attaches:
          - ZipCompression
          - StaticDataTable
          - RemoteImportStorageSetup
---
type: Program
spec:
  use: DecompressGzip
  root: GzipCompression
  dialect: Bash
  call: gunzip {command}
  kwargs:
    command:
      type: MultipleAncestorsArgument
      spec:
        name: command
        call: >
            format!(
                "--suffix=downloaded -c {tmp_dir}/{archive_name}.downloaded > {tmp_dir}/{archive_name}.txt",
                tmp_dir=remote_import_storage_setup.tmp_dir,
                archive_name=static_data_table.name,
            )
        attaches:
          - StaticDataTable
          - RemoteImportStorageSetup
---
type: Program
spec:
  use: RemoveFileHeader
  root: FileHeader
  dialect: Bash
  call: tail -n +{n} {tmp_dir}/{file_name}.txt > {tmp_dir}/{file_name}.no_header && rm {tmp_dir}/{file_name}.txt
  kwargs:
    n:
      type: AncestorArgument
      spec:
        attaches: FileHeader
        call: format!("{}", file_header.get_num_lines() + 1)
    tmp_dir:
      type: AncestorArgument
      spec:
        call: remote_import_storage_setup.tmp_dir
        attaches: RemoteImportStorageSetup
        name: tmp_dir
    file_name:
      type: AncestorArgument
      spec:
        call: static_data_table.name
        attaches: StaticDataTable
        name: file_name
---
type: Program
spec:
  use: ConvertCSVToOrc
  root: RemoteImportStorageSetup
  dialect: Bash
  call: >
    csv-import {tmp_dir}/{table_name}.no_header
    {tmp_dir}/{table_name}.no_header
  kwargs:
    tmp_dir:
      type: AncestorArgument
      spec:
        call: remote_import_storage_setup.tmp_dir
        attaches: RemoteImportStorageSetup
    table_name:
      type: AncestorArgument
      spec:
        call: static_data_table.name
        attaches: StaticDataTable
    schema:
      type: MultipleAncestorsArgument
      spec:
        call: >
          {
            let DataSchema::TabularSchema(ref t) = static_data_table.schema;
            let attributes = t.attributes.clone();
            let attr_v = data_set
                .datumTemplates
                .iter()
                .filter(|x| {
                    x.get_name().clone() == t.datumTemplateName
                })
                .map(|x| match x {
                    DatumTemplate::KeyedStruct(k) => k.get_attributes(),
                    DatumTemplate::IdentifierTuple(t) => t.get_attributes(),
                })
                .next().unwrap();
            let attr_map = attr_v.iter()
                .map(|x| (x.get_name().clone(), x.get_orc_type()))
                .collect::<LinkedHashMap<String, String>>();
            let attr_types = attributes.iter().map(
                |x| format!(
                    "{}:{}",
                    x,
                    attr_map.get(x).unwrap().clone()
                ).to_string()
            ).collect::<Vec<String>>();
            format!("\n    {}    \n", attr_types.join(",")).to_string()
          }
        attaches:
          - StaticDataTable
          - DataSet

---
type: Program
spec:
  use: HiveDirectoriesCreated
  root: HiveLocation
  dialect: Presto
  call: CREATE SCHEMA IF NOT EXISTS {presto_schema} {location}
  kwargs:
    presto_schema:
      type: AncestorArgument
      spec:
        attaches: DataSet
        call: data_set.name.clone()
    location:
      type: MultipleAncestorsArgument
      spec:
        attaches:
           - HiveTableStorage
           - Universe
           - DataSet
        call: >
          match &hive_table_storage.location {
            HiveLocation::AlluxioLocation(a) => format!(
                "WITH (location='alluxio://{}:{}/{}/{}/{}')",
                universe.endpoints.alluxio.as_ref().unwrap().server,
                universe.endpoints.alluxio.as_ref().unwrap().rpcPort,
                universe.endpoints.alluxio.as_ref().unwrap().directory,
                data_set.name,
                a.path,
            ).to_string(),
            HiveLocation::MinioLocation(_) => format!(
                "WITH (location='s3a://{}/{}/')",
                universe.endpoints.minio.as_ref().unwrap().bucket,
                data_set.name,
            ).to_string(),
          }
---
type: Program
spec:
  use: TableSchemasCreated
  root: HiveTableStorage
  dialect: Presto
  call: |
      \nCREATE TABLE IF NOT EXISTS hive.{presto_schema}.{table_name}
      ({schema}) WITH (format='{data_format}')
  kwargs:
    table_name:
      type: AncestorArgument
      spec:
        call: static_data_table.name
        attaches: StaticDataTable
    data_format:
      type: AncestorArgument
      spec:
        call: >
          match &hive_table_storage.encoding {
            Encoding::ORCEncoding(_) => "ORC".to_string(),
            _ => panic!("Format not supported for hive table")
          }
        attaches: HiveTableStorage
    presto_schema:
      type: AncestorArgument
      spec:
        attaches: DataSet
        call: data_set.name.clone()
    schema:
      type: MultipleAncestorsArgument
      spec:
        call: >
          {
            use crate::attributes::TAttribute;
            let DataSchema::TabularSchema(ref t) = static_data_table.schema;
            let dictionary = Standard::from_embedded(Language::EnglishUS).unwrap();
            let options = Options::new(66).splitter(dictionary);

            let attr_v = data_set
                .datumTemplates
                .iter()
                .filter(|x| {
                    x.get_name().clone() == t.datumTemplateName
                })
                .map(|x| match x {
                    DatumTemplate::KeyedStruct(k) => k.get_attributes(),
                    DatumTemplate::IdentifierTuple(t) => t.get_attributes(),
                })
                .next().unwrap();
            let attr_map = attr_v.iter()
                .map(|x|
                    (x.get_name().clone(), (x.get_presto_type(), x.get_comment().clone())))
                .collect::<Vec<_>>();
            let attr_types = attr_map.iter().map(|x| {
                let (name, (presto_type, comment)) = x;
                let comment_str = match comment {
                    Some(c) => {
                        let cleaned_up_comment = c
                          .split("\n")
                          .into_iter()
                          .map(|x| x.to_string().trim().to_string())
                          .collect::<Vec<String>>().join(" ");
                        fill(cleaned_up_comment.trim(), &options)
                          .split("\n").map(|x| x.to_string()).collect::<Vec<String>>()
                    }
                    None => vec!["".to_string()],
                };
                if comment_str.len() == 1 {
                    return format!(
                        "    {} {} COMMENT '{}'",
                        name,
                        presto_type,
                        comment_str.get(0).unwrap().to_string().replace("\'", "`"),
                    ).to_string();
                } else {
                    return format!(
                        "    {} {} \n COMMENT {}\n",
                        name,
                        presto_type,
                        comment_str
                          .into_iter()
                          .map(|x| format!("        '{}'", x.to_string().replace("\'", "`")).to_string())
                          .collect::<Vec<String>>().join("\n")
                    ).to_string();
                }
            }).collect::<Vec<String>>();
            format!("\n{}    \n", attr_types.join(",\n"))
          }
        attaches:
          - StaticDataTable
          - DataSet
---
type: Program
spec:
  use: TableSchemasDroppedIfExisting
  root: HiveTableStorage
  dialect: Presto
  call: |
      \nDROP TABLE IF EXISTS hive.{presto_schema}.{table_name}
  kwargs:
    table_name:
      type: AncestorArgument
      spec:
        call: static_data_table.name
        attaches: StaticDataTable
    presto_schema:
      type: AncestorArgument
      spec:
        attaches: DataSet
        call: data_set.name.clone()
---
type: Program
spec:
  use: DroppedCSVTable
  root: HiveTableStorage
  dialect: Presto
  call: |
      \nDROP TABLE IF EXISTS hive.{presto_schema}.{table_name}_csv
  kwargs:
    table_name:
      type: AncestorArgument
      spec:
        call: static_data_table.name
        attaches: StaticDataTable
    presto_schema:
      type: AncestorArgument
      spec:
        attaches: DataSet
        call: data_set.name.clone()
---
type: Program
spec:
  use: CSVTableSchemasCreated
  root: HiveTableStorage
  dialect: Presto
  call: \nCREATE TABLE IF NOT EXISTS {presto_schema}.{table_name} \n({schema})\nWITH (format='CSV', external_location='{external_location}')\n
  kwargs:
    external_location:
      type: MultipleAncestorsArgument
      spec:
        attaches:
           - HiveTableStorage
           - Universe
           - StaticDataTable
           - DataSet
        call: >
          match &hive_table_storage.location {
            HiveLocation::AlluxioLocation(_) => format!(
                "alluxio://{}:{}/{}/{}/{}_csv",
                universe.endpoints.alluxio.as_ref().unwrap().server,
                universe.endpoints.alluxio.as_ref().unwrap().rpcPort,
                universe.endpoints.alluxio.as_ref().unwrap().directory,
                data_set.name,
                static_data_table.name,
            ).to_string(),
            HiveLocation::MinioLocation(_) => format!(
                "s3a://{}/{}/{}_csv/",
                universe.endpoints.minio.as_ref().unwrap().bucket,
                data_set.name,
                static_data_table.name,
            ).to_string(),
          }
    table_name:
      type: AncestorArgument
      spec:
        call: format!("{}_csv", static_data_table.name).to_string()
        attaches: StaticDataTable
    presto_schema:
      type: AncestorArgument
      spec:
        attaches: DataSet
        call: data_set.name.clone()
    schema:
      type: MultipleAncestorsArgument
      spec:
        call: >
          {
            use crate::attributes::TAttribute;
            let DataSchema::TabularSchema(ref t) = static_data_table.schema;
            let attr_v = data_set
                .datumTemplates
                .iter()
                .filter(|x| {
                    x.get_name().clone() == t.datumTemplateName
                })
                .map(|x| match x {
                    DatumTemplate::KeyedStruct(k) => k.get_attributes(),
                    DatumTemplate::IdentifierTuple(t) => t.get_attributes(),
                })
                .next().unwrap();
            let attr_map = attr_v.iter()
                .map(|x|
                    (x.get_name().clone(), "VARCHAR".to_string()))
                .collect::<Vec<_>>();
            let attr_types = attr_map.iter().map(|x| {
                let (name, presto_type) = x;
                return format!(
                    "    {} {}",
                    name,
                    presto_type,
                ).to_string();
            }).collect::<Vec<String>>();
            format!("\n{}\n", attr_types.join(",\n"))
          }
        attaches:
          - StaticDataTable
          - DataSet
---
type: Program
spec:
  use: ConvertToCSV
  root: RemoteStorage
  dialect: Bash
  call: >
    {call}
  kwargs:
    call:
      type: MultipleAncestorsArgument
      spec:
        call: >
          {
            let tmp_dir = &remote_import_storage_setup.tmp_dir;
            let file_name = &static_data_table.name;
            match &remote_storage.encoding {
               Encoding::CSVEncoding(_) => format!(
                  "mv {tmp_dir}/{file_name}.no_header {tmp_dir}/{file_name}.csv",
                  tmp_dir=tmp_dir,
                  file_name=file_name,
               ).to_string(),
               Encoding::TSVEncoding(_) => format!(
                  "cat {tmp_dir}/{file_name}.no_header | tr '\\\\t' ',' > {tmp_dir}/{file_name}.csv",
                  tmp_dir=tmp_dir,
                  file_name=file_name,
               ).to_string(),
              _ => panic!("Encoding not supported.")
            }
          }
        attaches:
          - StaticDataTable
          - RemoteImportStorageSetup
          - RemoteStorage
---
type: Program
spec:
  use: ConvertCSVTableToORCTable
  root: HiveTableStorage
  dialect: Presto
  call: \nINSERT INTO {presto_schema}.{table_name} \nSELECT {columns} \nFROM {presto_schema}.{table_name}_csv\n
  kwargs:
    table_name:
      type: AncestorArgument
      spec:
        call: format!("{}", static_data_table.name).to_string()
        attaches: StaticDataTable
    presto_schema:
      type: AncestorArgument
      spec:
        attaches: DataSet
        call: data_set.name.clone()
    columns:
      type: MultipleAncestorsArgument
      spec:
        call: >
          {
            use crate::attributes::TAttribute;
            let DataSchema::TabularSchema(ref t) = static_data_table.schema;
            let attr_v = data_set
                .datumTemplates
                .iter()
                .filter(|x| {
                    x.get_name().clone() == t.datumTemplateName
                })
                .map(|x| match x {
                    DatumTemplate::KeyedStruct(k) => k.get_attributes(),
                    DatumTemplate::IdentifierTuple(t) => t.get_attributes(),
                })
                .next().unwrap();
            let attr_map = attr_v.iter()
                .map(|x|
                    (x.get_name().clone(), x.get_presto_type()))
                .collect::<Vec<_>>();
            let attr_types = attr_map.iter().map(|x| {
                let (name, presto_type) = x;
                return format!(
                    "CAST({name} AS {presto_type}) AS {name}",
                    name=name,
                    presto_type=presto_type,
                ).to_string();
            }).collect::<Vec<String>>();
            format!("\n{}", attr_types.join(",\n"))
          }
        attaches:
          - StaticDataTable
          - DataSet
